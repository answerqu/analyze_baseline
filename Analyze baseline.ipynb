{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import uniform,expon\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objs as go\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "from sklearn import preprocessing \n",
    "from sklearn.metrics import log_loss,roc_auc_score,f1_score,precision_score,recall_score,confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV,validation_curve, train_test_split\n",
    "from hyperopt import hp, fmin, tpe, Trials, STATUS_OK,STATUS_FAIL\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore')\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################                  #################################################################\n",
    "###########################################  DATA PREPROCESSING  ############################################################### \n",
    "#############################################                  #################################################################\n",
    "\n",
    "# data - DataFrame to preprocess\n",
    "# encoder - encode method from sklearn.preprocessing \n",
    "# scaler - scale method from sklearn.preprocessing\n",
    "# random_state - not important param for multinomial distribution\n",
    "# fill_nan_cat, fill_nan_num - =some_value - method for categorical and numerical columns\n",
    "#                              ='top' - top feature for categorical columns\n",
    "#                              ='multinomial' - multinomial disrtibution for empty spaces in each column \n",
    "#                              ='median' or ='mean' - fill numerical NaN by mean or median\n",
    "#                                               \n",
    "# feature_exceptions_fill,feature_exceptions_encode,feature_exceptions_dummies - columns to not to fill|encode|dummie\n",
    "#                                                                                =['feature1','feature2',...]\n",
    "# features_list - features to scale by group\n",
    "#                  =[['feature11','feature12'],['feature21','feature22'],...]\n",
    "# dummies, drop_first - pd.get_dummies(df); \n",
    "#                       by default: both == False\n",
    "# drop_col - columns to drop \n",
    "\n",
    "\n",
    "def data_preprocessing(data,encoder=None,scaler=None,random_state=random.randrange(1,100),\n",
    "                       fill_nan_cat=None,fill_nan_num=None,\n",
    "                       feature_exceptions_fill=[],feature_exceptions_encode=[],feature_exceptions_dummies=[],\n",
    "                       features_list=[],scale_count=False,\n",
    "                       dummies=False,drop_first=False,\n",
    "                       drop_col=None):\n",
    "    cat_col = list(data.select_dtypes(include=['object']))\n",
    "    num_col = list(data.select_dtypes(include=['float64', 'int64']))\n",
    "    \n",
    "    if drop_col != None:\n",
    "        if drop_col == 'objective':\n",
    "            data.drop(cat_col,axis=1,inplace=True)\n",
    "        elif drop_col == 'numeric':\n",
    "            data.drop(num_col,axis=1,inplace=True) \n",
    "        else:\n",
    "            data.drop(drop_col,axis=1,inplace=True)\n",
    "        cat_col = list(data.select_dtypes(include=['object']))\n",
    "        num_col = list(data.select_dtypes(include=['float64', 'int64']))\n",
    "            \n",
    "    \n",
    "    if fill_nan_cat != None:\n",
    "        cat_col_fill = cat_col\n",
    "        for feature in feature_exceptions_fill:\n",
    "            cat_col_fill.remove(feature)\n",
    "        if fill_nan_cat == 'top':\n",
    "            for feature in cat_col_fill:\n",
    "                data[feature] = data[feature].fillna(data[feature].describe().top)\n",
    "        if fill_nan_cat == 'multinomial':\n",
    "            func = lambda x: np.argmax(x)\n",
    "            for feature in cat_col_fill:\n",
    "                if data[feature].isna().sum() != 0: \n",
    "                    data_nan_index = list(data[data[feature].isna() == True].index)\n",
    "                    num_tf = data[feature].isna().value_counts()\n",
    "                    prob_list = data[feature].value_counts().values/num_tf[0]\n",
    "                    indexes = data[feature].value_counts().index\n",
    "                    data_new = pd.Series(map(func, multinomial.rvs(n=1,p=prob_list,size=num_tf[1],random_state=random_state)), \n",
    "                                             index = data_nan_index).apply(lambda x: indexes[x])\n",
    "                    data.iloc[data_nan_index, list(data.columns).index(feature)] = data_new\n",
    "        else:\n",
    "            data[cat_col_fill] = data[cat_col_fill].fillna(fill_nan_cat)\n",
    "                                         \n",
    "    if fill_nan_num != None:\n",
    "        num_col_fill = num_col\n",
    "        for feature in feature_exceptions_fill:\n",
    "            num_col_fill.remove(feature)                           \n",
    "        if fill_nan_num == 'mean':\n",
    "            for feature in num_col_fill:\n",
    "                data[feature] = data[feature].fillna(data[feature].mean())\n",
    "        if fill_nan_num == 'median':\n",
    "            for feature in num_col_fill:\n",
    "                data[feature] = data[feature].fillna(data[feature].median())\n",
    "        else:\n",
    "            data[num_col_fill] = data[num_col_fill].fillna(fill_nan_num)\n",
    "                                         \n",
    "    if encoder != None:\n",
    "        cat_col_encode = cat_col\n",
    "        for feature in feature_exceptions_encode:\n",
    "            cat_col_encode.remove(feature)\n",
    "        for feature in cat_col_encode:\n",
    "            data[feature] = encoder.fit_transform(data[feature])\n",
    "    \n",
    "    if dummies:\n",
    "        cat_col_dummies = cat_col\n",
    "        for feature in feature_exceptions_dummies:\n",
    "            cat_col_dummies.remove(feature)\n",
    "        data = pd.get_dummies(data,drop_first=drop_first,columns = cat_col_dummies)\n",
    "    \n",
    "    if scaler != None:\n",
    "        if scale_count:\n",
    "            for features_scale in features_list:\n",
    "                data_array = np.transpose(scaler.fit_transform(data[features_scale]))\n",
    "                for i in range(len(features_scale)):\n",
    "                    data[features_scale[i]] = data_array[i]\n",
    "        else:\n",
    "            data_array = np.transpose(scaler.fit_transform(data[features_list]))\n",
    "            for i in range(len(features_list)):\n",
    "                data[features_list[i]] = data_array[i]\n",
    "    return data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_preprocessing(data,scaler=True,random_state=42,\n",
    "                       fill_nan_cat='multinomial',fill_nan_num='median',\n",
    "                       feature_exceptions_fill=['col0'], \n",
    "                       features_list=[['feat1','feat2'],['feat3','feat4']], scale_count=True,\n",
    "                       dummies=True,drop_col=['col1','col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################              ####################################################################\n",
    "###########################################  MODEL TRAINING  ################################################################## \n",
    "#############################################              ####################################################################\n",
    "\n",
    "# X,y -data,target\n",
    "# test_size - test size for train_test_split()\n",
    "# task_type = 'classification' or 'regression', for now only 'classification' available\n",
    "# score - type of scoring to raise\n",
    "# CCV - if True: make a cross validation if False: don't\n",
    "# cv - number of folds for CCV\n",
    "# score_matrix_print - if True: print score dataframe with models for columns and scorings for indexes\n",
    "# alg_list_clf_names - list of algorithms names (using for printing info)\n",
    "# alg_list_clf - list of sklearn models\n",
    "# params_distribution - list of dictionaries of parameters distribution of each model for GridSearchCV; \n",
    "# plot - if True: plot validation curve for each parameter in params_distribution\n",
    "\n",
    "\n",
    "\n",
    "n_iters = 50\n",
    "random_state = 42\n",
    "\n",
    "alg_list_clf= [ DecisionTreeClassifier(random_state= random_state),\n",
    "               LogisticRegression(),\n",
    "                GaussianNB(),\n",
    "            SGDClassifier(max_iter= 200,random_state= random_state),\n",
    "            KNeighborsClassifier(),\n",
    "            SVC()\n",
    "            ]\n",
    "\n",
    "alg_list_clf_names = ['Decision Tree Classifier','Logistic regression', 'Naive Bayes', 'SGD', 'kNN',  'Support Vector Machines (SVC)']\n",
    "\n",
    "params_distribution=[{'max_depth': range(4,13),\n",
    "                      'min_samples_split': np.arange(2,41,5),\n",
    "                      'min_samples_leaf': np.arange(2,21,5),\n",
    "\n",
    "                     }, \n",
    "    \n",
    "                    #logreg\n",
    "                     {'C': np.logspace(-3,3,n_iters),\n",
    "                      #'solver': ['liblinear','lbfgs',***],\n",
    "                      #'class_weight':\n",
    "                      #'penalty': ['l1','l2','elasticnet'],\n",
    "\n",
    "                     },\n",
    "                    \n",
    "                     #NB\n",
    "                      {},                   \n",
    "                      \n",
    "                    #SGD\n",
    "                     {'alpha': np.logspace(-3, 3, n_iters), # learning rate\n",
    "                      \n",
    "                      #'loss': ['log','hinge','modified_huber'],\n",
    "                      #'penalty': ['l2','l1','elasticnet'],\n",
    "  \n",
    "                     },\n",
    "    \n",
    "                    #kNN\n",
    "                    {'n_neighbors': range(1,12),   \n",
    "                    },\n",
    "                    #tree\n",
    "                     \n",
    "    \n",
    "                    #SVM\n",
    "                    {'C': np.logspace(-3,3,n_iters),\n",
    "                     }]\n",
    "\n",
    "def model_train_light(X,y,test_size=0.25,task_type='classification',score='roc_auc',CCV=False,cv=3,score_matrix_print=True,\n",
    "                      random_state=random_state,alg_list_clf_names = alg_list_clf_names,\n",
    "                      alg_list_clf=alg_list_clf,params_distribution=params_distribution,\n",
    "                      plot=False):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = test_size,random_state=random_state,shuffle=True)\n",
    "    list_of_models = []\n",
    "    score_matrix = []\n",
    "    if task_type == 'classification': #lr,B, SGD, kNN, tree, SVM, RFM\n",
    "        for light_clf in alg_list_clf:\n",
    "            if (alg_list_clf.index(light_clf) != -1):\n",
    "                curr_index = alg_list_clf.index(light_clf)                    \n",
    "                if CCV:\n",
    "                    curr_grid_model = GridSearchCV(light_clf,param_grid=params_distribution[curr_index],\n",
    "                                                  scoring=score,cv=cv)\n",
    "                    curr_grid_model.fit(X,y)\n",
    "                    print('MODEL: ', alg_list_clf_names[curr_index])\n",
    "                    print('Best score on CCV: ', curr_grid_model.best_score_)\n",
    "                    print('Best parameters on CCV: ', curr_grid_model.best_params_)\n",
    "                    print()\n",
    "                else:\n",
    "                    curr_grid_model = light_clf\n",
    "                    print('MODEL: ', alg_list_clf_names[curr_index])\n",
    "                    print('Best score on CCV: ', curr_grid_model.best_score_)\n",
    "                    print('Best parameters on CCV: ', curr_grid_model.best_params_)\n",
    "                    print()\n",
    "                if plot:\n",
    "                    lw=2\n",
    "                    for param in list(curr_grid_model.best_params_.keys()):\n",
    "                        param_range = params_distribution[curr_index][param]\n",
    "                        train_scores, test_scores = validation_curve(light_clf, X, y, param_name=param,\n",
    "                                                                         param_range=param_range,scoring=score)\n",
    "                        train_scores_mean = np.mean(train_scores, axis=1)\n",
    "                        train_scores_std = np.std(train_scores, axis=1)\n",
    "                        test_scores_mean = np.mean(test_scores, axis=1)\n",
    "                        test_scores_std = np.std(test_scores, axis=1)\n",
    "                        plt.figure(figsize=(12,8))\n",
    "                        plt.title('Validation Curve for ' + str(alg_list_clf_names[curr_index]))\n",
    "                        plt.xlabel(param)\n",
    "                        plt.ylabel(str(score) + \" score\")\n",
    "                        plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "                                         color=\"darkorange\", lw=lw)\n",
    "                        plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                                             train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                                             color=\"darkorange\", lw=lw)\n",
    "                        plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                                         color=\"navy\", lw=lw)\n",
    "                        plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                                             test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                                             color=\"navy\", lw=lw)\n",
    "                        plt.legend(loc=\"best\")\n",
    "                        plt.show()\n",
    "                if score_matrix_print:\n",
    "                    score_array = np.array([accuracy_score(y_test,curr_grid_model.predict(X_test)),\n",
    "                                            precision_score(y_test,curr_grid_model.predict(X_test)),\n",
    "                                            recall_score(y_test,curr_grid_model.predict(X_test)),\n",
    "                                            f1_score(y_test,curr_grid_model.predict(X_test)),\n",
    "                                            roc_auc_score(y_test,curr_grid_model.predict(X_test))],dtype='float64')\n",
    "                    score_matrix.append(score_array)\n",
    "                    print(confusion_matrix(y_test,curr_grid_model.predict(X_test))) \n",
    "                    print()\n",
    "                    print('#####################')\n",
    "                    print()\n",
    "                list_of_models.append(curr_grid_model)\n",
    "    if score_matrix:\n",
    "        scoring=['accuracy','precicion', 'recall', 'f1', 'roc_auc_score']\n",
    "        score_df = pd.DataFrame(score_matrix, columns=scoring,index = alg_list_clf_names)\n",
    "    return score_df, list_of_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_light = model_train_light(X,y,test_size=0.33,task_type='classification',score='f1',\n",
    "                                CCV=True,cv=5,score_matrix_print=True,\n",
    "                      random_state=42,alg_list_clf_names = alg_list_clf_names,\n",
    "                      alg_list_clf=alg_list_clf,params_distribution=params_distribution,\n",
    "                      plot=True):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
